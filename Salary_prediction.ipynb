{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "from sklearn import datasets, preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "input_features = pd.read_csv('DSciHomeworkAssignmentV2/train_features.csv')\n",
    "input_salaries = pd.read_csv('DSciHomeworkAssignmentV2/train_salaries.csv')\n",
    "input_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zikki/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobId</th>\n",
       "      <th>companyId</th>\n",
       "      <th>yearsExperience</th>\n",
       "      <th>milesFromMetropolis</th>\n",
       "      <th>jobType_CEO</th>\n",
       "      <th>jobType_CFO</th>\n",
       "      <th>jobType_CTO</th>\n",
       "      <th>jobType_JANITOR</th>\n",
       "      <th>jobType_JUNIOR</th>\n",
       "      <th>jobType_MANAGER</th>\n",
       "      <th>...</th>\n",
       "      <th>major_MATH</th>\n",
       "      <th>major_NONE</th>\n",
       "      <th>major_PHYSICS</th>\n",
       "      <th>industry_AUTO</th>\n",
       "      <th>industry_EDUCATION</th>\n",
       "      <th>industry_FINANCE</th>\n",
       "      <th>industry_HEALTH</th>\n",
       "      <th>industry_OIL</th>\n",
       "      <th>industry_SERVICE</th>\n",
       "      <th>industry_WEB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JOB1362684407687</td>\n",
       "      <td>37</td>\n",
       "      <td>-0.276245</td>\n",
       "      <td>1.159051</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOB1362684407688</td>\n",
       "      <td>19</td>\n",
       "      <td>-1.246797</td>\n",
       "      <td>0.812763</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JOB1362684407689</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.276245</td>\n",
       "      <td>-0.399244</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JOB1362684407690</td>\n",
       "      <td>38</td>\n",
       "      <td>-0.553546</td>\n",
       "      <td>-1.126448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JOB1362684407691</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.553546</td>\n",
       "      <td>-1.161077</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              jobId  companyId  yearsExperience  milesFromMetropolis  \\\n",
       "0  JOB1362684407687         37        -0.276245             1.159051   \n",
       "1  JOB1362684407688         19        -1.246797             0.812763   \n",
       "2  JOB1362684407689         52        -0.276245            -0.399244   \n",
       "3  JOB1362684407690         38        -0.553546            -1.126448   \n",
       "4  JOB1362684407691          7        -0.553546            -1.161077   \n",
       "\n",
       "   jobType_CEO  jobType_CFO  jobType_CTO  jobType_JANITOR  jobType_JUNIOR  \\\n",
       "0            0            1            0                0               0   \n",
       "1            1            0            0                0               0   \n",
       "2            0            0            0                0               0   \n",
       "3            0            0            0                0               0   \n",
       "4            0            0            0                0               0   \n",
       "\n",
       "   jobType_MANAGER      ...       major_MATH  major_NONE  major_PHYSICS  \\\n",
       "0                0      ...                1           0              0   \n",
       "1                0      ...                0           1              0   \n",
       "2                0      ...                0           0              1   \n",
       "3                1      ...                0           0              0   \n",
       "4                0      ...                0           0              1   \n",
       "\n",
       "   industry_AUTO  industry_EDUCATION  industry_FINANCE  industry_HEALTH  \\\n",
       "0              0                   0                 0                1   \n",
       "1              0                   0                 0                0   \n",
       "2              0                   0                 0                1   \n",
       "3              1                   0                 0                0   \n",
       "4              0                   0                 1                0   \n",
       "\n",
       "   industry_OIL  industry_SERVICE  industry_WEB  \n",
       "0             0                 0             0  \n",
       "1             0                 0             1  \n",
       "2             0                 0             0  \n",
       "3             0                 0             0  \n",
       "4             0                 0             0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_id = input_features['companyId'].apply(lambda x: int(x[4:]))\n",
    "input_features['companyId'] = company_id\n",
    "\n",
    "#encode jobType, degree, major, industry\n",
    "input_features = pd.get_dummies(input_features, columns=['jobType', 'degree', 'major', 'industry'])\n",
    "\n",
    "#standardize yearsExperience, milesFromMetropolis\n",
    "input_features['yearsExperience'] = preprocessing.scale(input_features['yearsExperience'])\n",
    "input_features['milesFromMetropolis'] = preprocessing.scale(input_features['milesFromMetropolis'])\n",
    "input_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Complete\n"
     ]
    }
   ],
   "source": [
    "#create training & validation sets\n",
    "data = pd.merge(input_features, input_salaries, how = \"left\", on= \"jobId\")\n",
    "train =  data.sample(frac=0.80,random_state= 100)\n",
    "validate = data.drop(train.index)\n",
    "\n",
    "train_x = train.iloc[:, 2:33]\n",
    "train_y = train.iloc[:, 33]\n",
    "\n",
    "validate_x = validate.iloc[:, 2:33]\n",
    "validate_y = validate.iloc[:, 33]\n",
    "\n",
    "print(\"Preprocessing Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranking [0.13966116 0.15562554 0.02747611 0.02859832 0.0263177  0.0085795\n",
      " 0.02418187 0.02620909 0.02269765 0.02606429 0.035585   0.03667101\n",
      " 0.01299595 0.03102375 0.01516797 0.02251665 0.02233565 0.01943962\n",
      " 0.01737619 0.02523168 0.02143064 0.0174848  0.01730379 0.0181726\n",
      " 0.02874312 0.02497828 0.02997394 0.0270779  0.03301477 0.02928613\n",
      " 0.02877932]\n",
      "salary_predictions [116.07314  137.46407  125.65225  ... 127.916245 119.1691    63.41762 ]\n",
      "Root Mean Squared Error:  18.828710483465915\n",
      "Variance Explained (R^2):  0.7635836977521642\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "#model = ExtraTreesRegressor(n_estimators=100)\n",
    "#model = GradientBoostingRegressor(min_samples_leaf= 4, learning_rate= 0.1, max_depth= 4)\n",
    "model = xgboost.XGBRegressor(colsample_bytree=0.4,\n",
    "                 gamma=0,               \n",
    "                 learning_rate=0.1,\n",
    "                 max_depth=6,\n",
    "                 min_child_weight=1.5,\n",
    "                 n_estimators=500,                                                                    \n",
    "                 reg_alpha=0.75,\n",
    "                 reg_lambda=0.45,\n",
    "                 subsample=0.6,\n",
    "                 seed=42)\n",
    "## 18.87\n",
    "model.fit(train_x,train_y)\n",
    "x = model.feature_importances_\n",
    "print(\"ranking\",x)\n",
    "\n",
    "predictions = model.predict(validate_x)\n",
    "print(\"salary_predictions\",predictions)\n",
    "print('Root Mean Squared Error: ', np.sqrt(mean_squared_error(validate_y, predictions)))\n",
    "print('Variance Explained (R^2): ', r2_score(validate_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3062\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3063\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3064\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-105826782af3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__delitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2738\u001b[0m             \u001b[0;31m# there was no match, this call should raise the appropriate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2739\u001b[0m             \u001b[0;31m# exception:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2740\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2742\u001b[0m         \u001b[0;31m# delete from the caches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   4172\u001b[0m         \u001b[0mDelete\u001b[0m \u001b[0mselected\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m         \"\"\"\n\u001b[0;32m-> 4174\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4176\u001b[0m         \u001b[0mis_deleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3063\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3065\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "\n",
    "target = 'loss'\n",
    "del train[target]\n",
    "del validate[target]\n",
    "\n",
    "def objective(space):\n",
    "    model = xgboost.XGBRegressor(n_estimators = 100,\n",
    "                            max_depth = space['max_depth'],\n",
    "                            min_child_weight = space['min_child_weight'],\n",
    "                            subsample = space['subsample'])\n",
    "\n",
    "    eval_set  = [( train_x, train_y), ( validate_x, validate_y)]\n",
    "\n",
    "    model.fit(train_x, train_y,eval_set=eval_set,\n",
    "            eval_metric = 'mae')\n",
    "    predictions = model.predict(validate_x)\n",
    "    mse = np.sqrt(mean_squared_error(validate_y, predictions))\n",
    "    print('MSE:', mse)\n",
    "    return{'loss':mse, 'status': STATUS_OK }\n",
    "\n",
    "\n",
    "space ={\n",
    "        'max_depth': hp.quniform(\"x_max_depth\", 5, 10, 1),\n",
    "        'min_child_weight': hp.quniform ('x_min_child', 1, 10, 1),\n",
    "        'subsample': hp.uniform ('x_subsample', 0.8, 1)\n",
    "    }\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=3,\n",
    "            trials=trials)\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
